{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["DiYdg1jDGBhk"],"machine_shape":"hm","authorship_tag":"ABX9TyPc8SoAzTmaHC+zpIcamMdk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install pvlib\n","# 1. 卸载导致冲突的库\n","# -y 选项可以自动确认卸载，无需手动输入 'y'\n","!pip uninstall -y tensorflow numba\n","\n","# 2. 重新运行高效的 PyG 安装脚本\n","import torch\n","\n","# 检测当前 PyTorch 和 CUDA 版本\n","TORCH = torch.__version__.split('+')[0]\n","# 确保 CUDA 版本字符串正确处理，例如 '12.4' 变为 'cu124'\n","if torch.version.cuda:\n","    CUDA = \"cu\" + torch.version.cuda.replace('.', '')\n","else:\n","    CUDA = 'cpu'\n","\n","# 打印检测到的版本，方便确认\n","print(f\"PyTorch version: {TORCH}\")\n","print(f\"CUDA version: {CUDA}\")\n","\n","# 使用 -q (quiet) 参数减少输出\n","# 使用 --no-cache-dir 避免使用缓存\n","!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n","!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n","!pip install -q torch-cluster -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n","!pip install -q torch-geometric\n","\n","# 3. 验证安装\n","try:\n","    import torch_geometric\n","    print(\"\\nPyG installation successful!\")\n","    print(f\"PyG version: {torch_geometric.__version__}\")\n","except ImportError:\n","    print(\"\\nPyG installation failed.\")"],"metadata":{"id":"hSAIiZqdxxdP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# GraphData Construction"],"metadata":{"id":"DiYdg1jDGBhk"}},{"cell_type":"code","source":["# %%capture\n","# !pip install torch_geometric\n","# !pip install pvlib # 需要安装此库用于太阳位置计算\n","\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn.functional as F\n","from torch_geometric.data import Data\n","from torch_geometric.utils import to_networkx\n","from torch_scatter import scatter_mean # Assuming torch_scatter is available if add_neighbor_agg=True\n","\n","\n","import networkx as nx\n","import pickle\n","import re\n","# import textwrap # Removed unused\n","from pathlib import Path\n","import scipy.sparse.linalg as spla\n","from sklearn.metrics import pairwise_distances\n","\n","import pvlib # 用于太阳位置计算\n","from datetime import datetime, timezone # timezone需要显式导入\n","import math\n","\n","# ==================== 太阳位置计算模块 ====================\n","class SolarCalculator:\n","    def __init__(self, latitude, longitude, altitude=0, timezone_str='Asia/Singapore'):\n","        self.latitude = latitude\n","        self.longitude = longitude\n","        self.altitude = altitude\n","        self.timezone_str = timezone_str\n","\n","    def get_solar_position(self, year, month, day, hour_of_day):\n","        dt_local = datetime(year, month, day, hour_of_day, 0, 0)\n","        dt_aware_local = pd.Timestamp(dt_local, tz=self.timezone_str)\n","        times = pd.DatetimeIndex([dt_aware_local])\n","\n","        solar_position = pvlib.solarposition.get_solarposition(\n","            time=times,\n","            latitude=self.latitude,\n","            longitude=self.longitude,\n","            altitude=self.altitude,\n","            temperature=25, # 平均温度，对太阳位置影响不大\n","            pressure=pvlib.atmosphere.alt2pres(self.altitude)\n","        )\n","        azimuth_deg = solar_position['azimuth'].iloc[0]\n","        elevation_deg = solar_position['elevation'].iloc[0]\n","\n","        return {\n","            'azimuth_deg': azimuth_deg,\n","            'elevation_deg': elevation_deg,\n","            'azimuth_rad': math.radians(azimuth_deg),\n","            'elevation_rad': math.radians(elevation_deg)\n","        }\n","\n","# ==================== CSV气象数据处理模块 ===================\n","class CSVWeatherParser:\n","    def __init__(self, csv_path: str):\n","        self.required_columns = [\n","            'Dry Bulb Temperature {C}', 'Relative Humidity {%}',\n","            'Wind Speed {m/s}', 'Atmospheric Pressure {Pa}',\n","            'Global Horizontal Radiation {Wh/m2}', 'Wind Direction {deg}'\n","        ]\n","        self.df = self._load_and_preprocess_csv(csv_path)\n","\n","    def _load_and_preprocess_csv(self, path: str) -> pd.DataFrame:\n","        try:\n","            df = pd.read_csv(path)\n","        except Exception as e:\n","            raise ValueError(f\"无法读取CSV文件 '{path}': {e}\")\n","\n","        expected_datetime_cols = ['Date', 'HH:MM']\n","        for col in expected_datetime_cols:\n","            if col not in df.columns:\n","                raise ValueError(f\"CSV文件 '{path}' 缺少必要的日期/时间列: '{col}'\")\n","        try:\n","            df['datetime'] = pd.to_datetime(\n","                df['Date'].astype(str) + ' ' + df['HH:MM'].astype(str),\n","                format='%Y/%m/%d %H:%M', errors='raise'\n","            )\n","        except Exception as e:\n","            raise ValueError(f\"解析日期时间列时出错: {e}.\")\n","\n","        df['month'] = df['datetime'].dt.month\n","        df['day'] = df['datetime'].dt.day\n","        df['hour'] = df['datetime'].dt.hour\n","\n","        all_required_data_cols = self.required_columns.copy()\n","        for col_name_csv in all_required_data_cols: # Renamed to avoid conflict\n","            if col_name_csv not in df.columns:\n","                raise ValueError(f\"CSV文件 '{path}' 缺少必要的气象数据列: '{col_name_csv}'\")\n","            df[col_name_csv] = pd.to_numeric(df[col_name_csv], errors='coerce')\n","        return df\n","\n","    def get_hourly_data(self, target_month: int, target_day: int, target_hour: int) -> dict:\n","        mask = (\n","            (self.df['month'] == target_month) &\n","            (self.df['day'] == target_day) &\n","            (self.df['hour'] == target_hour)\n","        )\n","        selected_data = self.df[mask]\n","        fallback_data = pd.DataFrame() # Initialize to empty dataframe\n","\n","        if selected_data.empty:\n","            fallback_mask = (self.df['month'] == target_month) & (self.df['hour'] == target_hour)\n","            fallback_data = self.df[fallback_mask]\n","            if not fallback_data.empty:\n","                print(f\"警告: 未找到 {target_month}-{target_day} {target_hour}:00 的精确气象数据。将使用该月该小时的平均/首条记录。\")\n","                selected_data = fallback_data.iloc[[0]]\n","            else:\n","                raise ValueError(f\"未找到气象数据：月份={target_month}, 日期={target_day}, 小时={target_hour}, 且无回退数据。\")\n","\n","        if len(selected_data) > 1 and (fallback_data.empty or (not fallback_data.empty and len(fallback_data) > 1)):\n","            print(f\"警告: 找到 {len(selected_data)} 条记录：月份={target_month}, 日期={target_day}, 小时={target_hour}. 将使用第一条记录。\")\n","\n","        row = selected_data.iloc[0].copy()\n","        for col_name_csv in self.required_columns: # Renamed to avoid conflict\n","            if pd.isna(row[col_name_csv]):\n","                mean_val = self.df[(self.df['month'] == target_month) & (self.df['hour'] == target_hour)][col_name_csv].mean()\n","                if pd.notna(mean_val):\n","                    print(f\"警告: 在 {target_month}-{target_day} {target_hour}:00 的数据中，列 '{col_name_csv}' 无效(NaN)。已用月均值 {mean_val:.2f} 填充。\")\n","                    row[col_name_csv] = mean_val\n","                else:\n","                    raise ValueError(f\"在 {target_month}-{target_day} {target_hour}:00 的数据中，列 '{col_name_csv}' 包含无效值 (NaN) 且无法用月均值填充。\")\n","\n","        wind_direction_deg_raw = row['Wind Direction {deg}']\n","        wind_blowing_to_meteo_deg = (wind_direction_deg_raw + 180) % 360\n","\n","        hourly_params = {\n","            'temperature_c': row['Dry Bulb Temperature {C}'],\n","            'humidity_percent': row['Relative Humidity {%}'],\n","            'wind_speed_mps': row['Wind Speed {m/s}'],\n","            'pressure_pa': row['Atmospheric Pressure {Pa}'],#只是不要这个参数了\n","            'global_horizontal_radiation_whm2': row['Global Horizontal Radiation {Wh/m2}'],\n","            'wind_direction_from_deg': wind_direction_deg_raw,\n","            'wind_blowing_to_meteo_deg': wind_blowing_to_meteo_deg,\n","            'wind_blowing_to_meteo_rad': math.radians(wind_blowing_to_meteo_deg)\n","        }\n","        return hourly_params\n","\n","# ==================== 数据预处理模块 ===================\n","class ClimateDataPreprocessor:\n","    def __init__(self, input_path, output_path, window_size=50, stride=40,\n","                 global_tree_max=None, global_building_max=None):\n","        self.input_data = np.load(input_path).astype(np.float32)\n","        raw_output = np.load(output_path).astype(np.float32)\n","        self.window_size = window_size\n","        self.stride = stride\n","        self.building_mask_full = (self.input_data[:, :, 2] > 0)\n","        self.global_tree_max = global_tree_max if global_tree_max is not None else self.input_data[:, :, 0].max()\n","        if self.global_tree_max == 0: self.global_tree_max = 1.0\n","        self.global_building_max = global_building_max if global_building_max is not None else self.input_data[:, :, 2].max()\n","        if self.global_building_max == 0: self.global_building_max = 1.0\n","\n","        self.output_data, self.nan_report = self._process_nan(raw_output)\n","        self._validate_shapes()\n","\n","    def _validate_shapes(self):\n","        input_shape = self.input_data.shape\n","        output_shape = self.output_data.shape\n","        assert len(input_shape) == 3 and input_shape[:2] == (250, 250), \\\n","            f\"输入数据形状应为(250,250,3)，实际得到{input_shape}\"\n","        assert len(output_shape) == 4 and output_shape[1:3] == (250, 250), \\\n","            f\"输出数据形状应为(6,250,250,12)，实际得到{output_shape}\"\n","\n","    def _process_nan(self, raw_output):\n","        building_mask = self.building_mask_full\n","        nan_mask = np.isnan(raw_output)\n","        building_mask_expanded = building_mask[np.newaxis, :, :, np.newaxis]\n","        non_building_nan_initial = np.sum(nan_mask & ~building_mask_expanded)\n","        cleaned = raw_output.copy()\n","        for var_idx in range(cleaned.shape[0]):\n","            for t_idx in range(cleaned.shape[3]):\n","                slice_data = cleaned[var_idx, :, :, t_idx]\n","                mask_non_building_current_slice = ~building_mask\n","                valid_mean_non_building = np.nanmean(slice_data[mask_non_building_current_slice])\n","                if np.isnan(valid_mean_non_building):\n","                    valid_mean_non_building = 0\n","                slice_data[np.isnan(slice_data) & mask_non_building_current_slice] = valid_mean_non_building\n","                cleaned[var_idx, :, :, t_idx] = slice_data\n","        remaining_nan_in_non_building = np.sum(np.isnan(cleaned) & ~building_mask_expanded)\n","        replaced_count = non_building_nan_initial - remaining_nan_in_non_building\n","        report = {\n","            \"total_nan_raw\": np.sum(np.isnan(raw_output)),\n","            \"nan_in_buildings_raw\": np.sum(nan_mask & building_mask_expanded),\n","            \"nan_outside_buildings_raw\": non_building_nan_initial,\n","            \"total_nan_cleaned\": np.sum(np.isnan(cleaned)),\n","            \"nan_in_buildings_cleaned\": np.sum(np.isnan(cleaned) & building_mask_expanded),\n","            \"replaced_nan_outside_buildings\": replaced_count\n","        }\n","        if report[\"total_nan_cleaned\"] > report[\"nan_in_buildings_cleaned\"]:\n","                print(f\"Warning: NANs still exist outside building areas after cleaning. Count: {report['total_nan_cleaned'] - report['nan_in_buildings_cleaned']}\")\n","        return cleaned, report\n","\n","    def _generate_windows(self, data, is_output=False):\n","        h, w = data.shape[1:3] if is_output else data.shape[:2]\n","        windows = []\n","        for i in range(0, h - self.window_size + 1, self.stride):\n","            for j in range(0, w - self.window_size + 1, self.stride):\n","                if is_output:\n","                    window = data[:, i:i+self.window_size, j:j+self.window_size, :]\n","                else:\n","                    window = data[i:i+self.window_size, j:j+self.window_size]\n","                windows.append(window)\n","        return np.array(windows)\n","\n","    def process(self):\n","        input_features = self._create_input_features()\n","        input_windows = self._generate_windows(input_features)\n","        output_windows = self._generate_windows(self.output_data, is_output=True)\n","        return input_windows, output_windows\n","\n","    def _create_input_features(self):\n","        surface = self.input_data[:, :, 1].astype(int)\n","        surface_clipped = np.clip(surface, 1, 5)\n","        onehot = np.eye(5)[surface_clipped - 1]\n","        tree_norm = self.input_data[:, :, 0] / self.global_tree_max\n","        building_norm = self.input_data[:, :, 2] / self.global_building_max\n","        building_mask_float = self.building_mask_full.astype(float)\n","        # Base features: 1 (tree) + 5 (onehot) + 1 (bldg_norm) + 1 (bldg_mask) = 8 features\n","        return np.concatenate([\n","            tree_norm[..., None],\n","            onehot,\n","            building_norm[..., None],\n","            building_mask_float[..., None]\n","        ], axis=-1)\n","\n","# ==================== 图结构构建模块 (核心修改区域) ===================\n","# 定义边类型常量\n","EDGE_TYPE_TREE_ACTIVITY = 0.0\n","EDGE_TYPE_SHADOW = 1.0\n","EDGE_TYPE_LOCAL_WIND = 2.0 # 用于边缘节点和地面节点的局部连接\n","EDGE_TYPE_SIMILARITY = 3.0\n","EDGE_TYPE_INTERNAL_N8 = 4.0 # 新增：用于内部建筑/树木节点的N8连接\n","\n","class GraphConstructor:\n","    def __init__(self,\n","                 global_tree_max_val,\n","                 global_building_max_val,\n","                 grid_size=4,\n","                 k_similarity=8,\n","                 target_attr_index=5,\n","                 base_building_shadow_radius_max_grids=15,\n","                 base_tree_shadow_radius_max_grids=5,\n","                 base_tree_activity_radius_max_grids=4,\n","                 wind_effect_on_radius_factor=0.3,\n","                 max_expected_wind_speed=8.0,\n","                 shadow_angular_width_deg = 30.0,\n","                 base_edge_weight=1.0,\n","                 shadow_influence_weight_factor=1.5, # 在当前简化权重计算中未使用\n","                 wind_alignment_weight_factor=0.5,   # 在当前简化权重计算中未使用\n","                 distance_decay_factor_per_grid=0.1, # 用于非相似性边的衰减\n","                 similarity_dist_decay_factor_per_grid=0.005, # 新增：相似性边的专属衰减率 (例如，常规衰减率的一小部分)\n","                 actual_shadow_boost_factor=1.05,\n","                 tree_activity_height_influence_factor=0.2,\n","                 knn_node_feature_normalization_epsilon=1e-6,\n","                 internal_n8_weight=0.1 # 在当前简化权重计算中未使用\n","                ):\n","\n","        self.grid_size = grid_size\n","        self.k_similarity = k_similarity\n","        self.target_attr_index = target_attr_index\n","        self.global_tree_max = global_tree_max_val\n","        self.global_building_max = global_building_max_val\n","        self.base_building_shadow_radius_max_grids = base_building_shadow_radius_max_grids\n","        self.base_tree_shadow_radius_max_grids = base_tree_shadow_radius_max_grids\n","        self.base_tree_activity_radius_max_grids = base_tree_activity_radius_max_grids\n","        self.wind_effect_on_radius_factor = wind_effect_on_radius_factor\n","        self.max_expected_wind_speed = max_expected_wind_speed if max_expected_wind_speed > 0 else 1.0\n","        self.shadow_angular_width_rad = math.radians(shadow_angular_width_deg)\n","        self.base_edge_weight = base_edge_weight\n","        self.shadow_influence_weight_factor = shadow_influence_weight_factor\n","        self.wind_alignment_weight_factor = wind_alignment_weight_factor\n","        self.distance_decay_factor_per_grid = distance_decay_factor_per_grid\n","        self.similarity_dist_decay_factor_per_grid = similarity_dist_decay_factor_per_grid # 新增属性\n","        self.actual_shadow_boost_factor = actual_shadow_boost_factor\n","        self.knn_epsilon = knn_node_feature_normalization_epsilon\n","        self.internal_n8_weight = internal_n8_weight\n","        self.tree_activity_height_influence_factor = tree_activity_height_influence_factor # <<<< 保存新参数\n","\n","\n","    def _is_internal_node(self, r, c, window_h, window_w, hcoords, node_features_local, is_checking_tree: bool):\n","        neighbor_offsets = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n","        for dr_offset, dc_offset in neighbor_offsets:\n","            nr, nc = r + dr_offset, c + dc_offset\n","            if not (0 <= nr < window_h and 0 <= nc < window_w):\n","                return False\n","            neighbor_node_idx = hcoords.get((nr, nc))\n","            if neighbor_node_idx is None:\n","                 return False\n","            neighbor_feat = node_features_local[neighbor_node_idx]\n","            if is_checking_tree:\n","                if not (neighbor_feat[0] > 0):\n","                    return False\n","            else: # is_checking_building\n","                if not (neighbor_feat[7] > 0.5):\n","                    return False\n","        return True\n","\n","    def build_graph(self, input_window_base_features, output_window_all_hours,\n","                    hourly_weather_params: dict, solar_params: dict,\n","                    target_hour_index_in_day: int):\n","\n","        node_features_local, positions = self._extract_local_node_features(\n","            input_window_base_features\n","        )\n","        num_nodes = len(node_features_local)\n","\n","        graph_global_env_f = np.array([\n","            hourly_weather_params['temperature_c'],\n","            hourly_weather_params['humidity_percent'],\n","            hourly_weather_params['wind_speed_mps'],\n","            hourly_weather_params['pressure_pa'],\n","            hourly_weather_params['global_horizontal_radiation_whm2'],\n","            solar_params['azimuth_rad'],\n","            solar_params['elevation_rad']\n","        ], dtype=np.float32)\n","\n","        hcoords = {}\n","        window_h, window_w = input_window_base_features.shape[:2]\n","        for r_idx in range(window_h):\n","            for c_idx in range(window_w):\n","                node_idx = r_idx * window_w + c_idx\n","                hcoords[(r_idx, c_idx)] = node_idx\n","\n","        edge_index_dynamic, edge_attr_dynamic, edge_weights_dynamic = self._build_dynamic_local_edges(\n","            node_features_local, positions, hcoords, window_h, window_w,\n","            hourly_weather_params, solar_params\n","        )\n","\n","        edge_index_sim, edge_attr_sim, edge_weights_sim = self._build_edges_topk_feature_similarity(\n","            node_features_local, positions, hourly_weather_params, solar_params\n","        )\n","\n","        edge_index_final, edge_attr_final_no_weight, edge_weights_final = self._merge_undirected_edges(\n","            edge_index_dynamic, edge_attr_dynamic, edge_weights_dynamic,\n","            edge_index_sim, edge_attr_sim, edge_weights_sim\n","        )\n","\n","        node_targets = self._process_targets(output_window_all_hours, target_hour_index_in_day)\n","\n","        if edge_index_final.size > 0 and edge_index_final.max() >= num_nodes:\n","            raise ValueError(\n","                f\"检测到越界节点索引：edge_index 存在 {edge_index_final.max()}，节点总数仅 {num_nodes}！\"\n","            )\n","\n","        building_mask_for_window_flat = (input_window_base_features[:, :, 7].flatten() > 0.5)\n","\n","        if edge_weights_final.size > 0:\n","            edge_weights_reshaped = edge_weights_final.reshape(-1, 1)\n","            edge_attr_final_with_weight = np.concatenate([edge_attr_final_no_weight, edge_weights_reshaped], axis=-1)\n","        else:\n","            expected_cols = 5 + 1 # 4 local physical + 1 type + 1 weight\n","            edge_attr_final_with_weight = np.empty((0, expected_cols) , dtype=np.float32)\n","\n","        data = Data(\n","            x=torch.FloatTensor(node_features_local),\n","            edge_index=torch.LongTensor(edge_index_final).t().contiguous() if edge_index_final.size > 0 else torch.empty((2,0), dtype=torch.long),\n","            edge_attr=torch.FloatTensor(edge_attr_final_with_weight),\n","            edge_weight=torch.FloatTensor(edge_weights_final) if edge_weights_final.size > 0 else torch.empty(0, dtype=torch.float),\n","            y=torch.FloatTensor(node_targets),\n","            pos=torch.FloatTensor(positions),\n","            building_mask=torch.BoolTensor(building_mask_for_window_flat),\n","            hourly_weather=torch.FloatTensor([v for k,v in sorted(hourly_weather_params.items())]),\n","            solar_position=torch.FloatTensor([v for k,v in sorted(solar_params.items())]),\n","            graph_global_env_features=torch.FloatTensor(graph_global_env_f)\n","        )\n","        return data\n","\n","    def _extract_local_node_features(self, window_base_features):\n","        h, w, c_base = window_base_features.shape\n","        features_list = window_base_features.reshape(-1, c_base)\n","        positions_list = []\n","        for r_idx in range(h):\n","            for c_idx in range(w):\n","                positions_list.append([c_idx * self.grid_size, r_idx * self.grid_size])\n","        return np.array(features_list), np.array(positions_list)\n","\n","    def _process_targets(self, output_window_all_hours, target_hour_index_in_day):\n","        target_slice_one_hour = output_window_all_hours[\n","            self.target_attr_index, :, :, target_hour_index_in_day\n","        ]\n","        return target_slice_one_hour.reshape(-1, 1)\n","\n","    # 在 GraphConstructor 类中：\n","    def _calculate_edge_weight(self, dist_m, wind_align_cos, wind_speed, is_shadow_interaction, edge_type, tree_height_norm_factor=None):\n","        # dist_m: 边的物理距离（米）\n","        # edge_type: 当前边的类型\n","        # 其他参数 (wind_align_cos, wind_speed, is_shadow_interaction) 在此版本中暂时不用\n","\n","        current_weight = self.base_edge_weight  # 初始权重，例如 1.0\n","\n","        if edge_type == EDGE_TYPE_SIMILARITY:\n","            # 对相似性边应用专属的、更温和的线性距离衰减\n","            if self.similarity_dist_decay_factor_per_grid > 0 and dist_m > 0:\n","                dist_grids = dist_m / self.grid_size\n","                current_weight /= (1.0 + self.similarity_dist_decay_factor_per_grid * dist_grids)\n","            # 如果 similarity_dist_decay_factor_per_grid <= 0 (或 dist_m == 0), 权重保持为 base_edge_weight\n","\n","        else:\n","            # 对于其他类型的边，应用标准的线性距离衰减\n","            if self.distance_decay_factor_per_grid > 0 and dist_m > 0:\n","                dist_grids = dist_m / self.grid_size\n","                current_weight /= (1.0 + self.distance_decay_factor_per_grid * dist_grids)\n","            # 如果 distance_decay_factor_per_grid <= 0 (或 dist_m == 0), 权重保持为 base_edge_weight\n","\n","        # ----- 新增：基于树高对树木活动边权重进行微弱调节 -----\n","        if edge_type == EDGE_TYPE_TREE_ACTIVITY and \\\n","           tree_height_norm_factor is not None and \\\n","           self.tree_activity_height_influence_factor > 0:\n","            # tree_height_norm_factor 预期是归一化的 (0到1)\n","            # self.tree_activity_height_influence_factor 是一个小的正值, e.g., 0.1, 0.2, 0.3\n","            # 这会使得权重在原有基础上，根据树高乘以一个 (1 + 0) 到 (1 + factor*1) 的系数\n","            modulation = 1.0 + self.tree_activity_height_influence_factor * tree_height_norm_factor\n","            current_weight *= modulation\n","        # ----- 结束新增部分 -----\n","\n","        # ----- 新增：对被识别的阴影边进行微弱放大 -----\n","        if edge_type == EDGE_TYPE_SHADOW and is_shadow_interaction:\n","            current_weight *= self.actual_shadow_boost_factor\n","        # ----- 结束新增部分 -----\n","\n","        return max(current_weight, 0.01) # 保证权重不为0或负\n","\n","\n","    def _build_dynamic_local_edges(self, node_features_local, positions, hcoords,\n","                                   window_h, window_w,\n","                                   hourly_weather_params: dict, solar_params: dict):\n","        edge_index_list = []\n","        edge_attr_list = []\n","        edge_weights_list = []\n","        num_nodes = len(node_features_local)\n","\n","        sol_elev_rad = solar_params['elevation_rad']\n","        wind_speed = hourly_weather_params['wind_speed_mps'] # Still needed for _calculate_edge_weight signature\n","        wind_blowing_to_meteo_rad = hourly_weather_params['wind_blowing_to_meteo_rad']\n","        radiation = hourly_weather_params['global_horizontal_radiation_whm2']\n","        shadow_main_direction_meteo_rad = (solar_params['azimuth_rad'] + math.pi) % (2 * math.pi)\n","\n","        base_edge_attr_dim_no_globals = 4\n","\n","        for i in range(num_nodes):\n","            src_feat_local = node_features_local[i]\n","            src_pos = positions[i]\n","            src_grid_r, src_grid_c = int(round(src_pos[1]/self.grid_size)), int(round(src_pos[0]/self.grid_size))\n","\n","            is_tree_node = src_feat_local[0] > 0\n","            is_building_node = src_feat_local[7] > 0.5\n","            is_object_node = is_tree_node or is_building_node\n","            is_internal = False\n","\n","            if is_object_node:\n","                is_internal = self._is_internal_node(src_grid_r, src_grid_c, window_h, window_w, hcoords, node_features_local, is_checking_tree=is_tree_node)\n","\n","            if is_internal:\n","                edge_type_internal = EDGE_TYPE_INTERNAL_N8\n","                base_n8_radius_grids = 1\n","                for dr_n8 in range(-base_n8_radius_grids, base_n8_radius_grids + 1):\n","                    for dc_n8 in range(-base_n8_radius_grids, base_n8_radius_grids + 1):\n","                        if dr_n8 == 0 and dc_n8 == 0: continue\n","                        tgt_grid_r, tgt_grid_c = src_grid_r + dr_n8, src_grid_c + dc_n8\n","                        if (tgt_grid_r, tgt_grid_c) in hcoords:\n","                            j = hcoords[(tgt_grid_r, tgt_grid_c)]\n","                            dst_pos = positions[j]\n","                            dist = np.linalg.norm(src_pos - dst_pos)\n","                            wind_align_cos_internal = 0.0 # Placeholder for internal edges\n","\n","                            edge_index_list.append([i, j])\n","                            current_edge_attr = [dist, float(dc_n8), float(dr_n8), wind_align_cos_internal, edge_type_internal]\n","                            edge_attr_list.append(current_edge_attr)\n","                            # Pass all params, but only dist_m and edge_type will be used by simplified weight calc\n","                            weight = self._calculate_edge_weight(dist, wind_align_cos_internal, wind_speed, False, edge_type_internal)\n","                            edge_weights_list.append(weight)\n","            else:\n","                if is_tree_node:\n","                    edge_type = EDGE_TYPE_TREE_ACTIVITY\n","                    activity_rad_factor = np.clip(radiation / 1000, 0.5, 1.2)\n","                    tree_activity_radius_grids = int(round(self.base_tree_activity_radius_max_grids * activity_rad_factor))\n","                    tree_activity_radius_grids = max(1, tree_activity_radius_grids)\n","                    # --- 获取归一化树高 ---\n","                    # 假设 src_feat_local[0] 是归一化的树木高度 (来自 ClimateDataPreprocessor._create_input_features)\n","                    normalized_tree_height = src_feat_local[0]\n","                    # --- 结束获取 ---\n","                    for dr in range(-tree_activity_radius_grids, tree_activity_radius_grids + 1):\n","                      for dc in range(-tree_activity_radius_grids, tree_activity_radius_grids + 1):\n","                        if dr == 0 and dc == 0: continue\n","                        if dr*dr + dc*dc > tree_activity_radius_grids*tree_activity_radius_grids: continue\n","                        tgt_grid_r, tgt_grid_c = src_grid_r + dr, src_grid_c + dc\n","                        if (tgt_grid_r, tgt_grid_c) in hcoords:\n","                          j = hcoords[(tgt_grid_r, tgt_grid_c)]\n","                          dst_pos = positions[j]\n","                          dist = np.linalg.norm(src_pos - dst_pos)\n","                          vec_ij = dst_pos - src_pos\n","                          if np.linalg.norm(vec_ij) < 1e-6: continue\n","                          angle_ij_cartesian_rad = math.atan2(vec_ij[1], vec_ij[0])\n","                          wind_blowing_to_cartesian_rad = (math.pi/2 - wind_blowing_to_meteo_rad) % (2*math.pi)\n","                          wind_align_cos = math.cos(angle_ij_cartesian_rad - wind_blowing_to_cartesian_rad)\n","\n","                          edge_index_list.append([i, j])\n","                          current_edge_attr = [dist, float(dc), float(dr), wind_align_cos, edge_type]\n","                          edge_attr_list.append(current_edge_attr)\n","                          # --- 修改权重计算调用 ---\n","                          weight = self._calculate_edge_weight(\n","                            dist,\n","                            wind_align_cos,\n","                            wind_speed,\n","                            False, # is_shadow_interaction for tree activity is False\n","                            edge_type,\n","                            tree_height_norm_factor=normalized_tree_height # <<<< 传递归一化树高\n","                          )\n","                          # --- 结束修改 ---\n","                          edge_weights_list.append(weight)\n","\n","                if is_object_node and sol_elev_rad > math.radians(1.0):\n","                    edge_type = EDGE_TYPE_SHADOW\n","                    obj_height_norm = src_feat_local[0] if is_tree_node else src_feat_local[6]\n","                    obj_height_abs = obj_height_norm * (self.global_tree_max if is_tree_node else self.global_building_max)\n","                    shadow_length_m = obj_height_abs / math.tan(sol_elev_rad) if math.tan(sol_elev_rad) > 1e-6 else obj_height_abs * 1000\n","                    base_max_grids_for_obj = self.base_tree_shadow_radius_max_grids if is_tree_node else self.base_building_shadow_radius_max_grids\n","                    shadow_length_grids = min(int(round(shadow_length_m / self.grid_size)), base_max_grids_for_obj)\n","                    shadow_length_grids = max(1, shadow_length_grids)\n","                    max_iter_radius = shadow_length_grids\n","                    for dr_s in range(-max_iter_radius, max_iter_radius + 1):\n","                        for dc_s in range(-max_iter_radius, max_iter_radius + 1):\n","                            if dr_s == 0 and dc_s == 0: continue\n","                            dist_grid_sq = dr_s*dr_s + dc_s*dc_s\n","                            if dist_grid_sq == 0 or dist_grid_sq > shadow_length_grids*shadow_length_grids : continue\n","                            tgt_grid_r, tgt_grid_c = src_grid_r + dr_s, src_grid_c + dc_s\n","                            if (tgt_grid_r, tgt_grid_c) in hcoords:\n","                                angle_to_target_meteo_rad = math.atan2(dc_s, -dr_s)\n","                                angle_diff = abs(angle_to_target_meteo_rad - shadow_main_direction_meteo_rad)\n","                                angle_diff = min(angle_diff, 2*math.pi - angle_diff)\n","                                if angle_diff <= self.shadow_angular_width_rad / 2.0:\n","                                    j = hcoords[(tgt_grid_r, tgt_grid_c)]\n","                                    dst_pos = positions[j]\n","                                    dist = np.linalg.norm(src_pos - dst_pos)\n","                                    vec_ij = dst_pos - src_pos\n","                                    if np.linalg.norm(vec_ij) < 1e-6: continue\n","                                    angle_ij_cartesian_rad = math.atan2(vec_ij[1], vec_ij[0])\n","                                    wind_blowing_to_cartesian_rad = (math.pi/2 - wind_blowing_to_meteo_rad) % (2*math.pi)\n","                                    wind_align_cos = math.cos(angle_ij_cartesian_rad - wind_blowing_to_cartesian_rad)\n","                                    edge_index_list.append([i, j])\n","                                    current_edge_attr = [dist, float(dc_s), float(dr_s), wind_align_cos, edge_type]\n","                                    edge_attr_list.append(current_edge_attr)\n","                                    weight = self._calculate_edge_weight(dist, wind_align_cos, wind_speed, True, edge_type) # is_shadow_interaction = True\n","                                    edge_weights_list.append(weight)\n","\n","                edge_type_local_wind = EDGE_TYPE_LOCAL_WIND\n","                base_local_radius_grids = 1 if not is_object_node else 2\n","                for dr_w in range(-base_local_radius_grids, base_local_radius_grids + 1):\n","                    for dc_w in range(-base_local_radius_grids, base_local_radius_grids + 1):\n","                        if dr_w == 0 and dc_w == 0: continue\n","                        tgt_grid_r, tgt_grid_c = src_grid_r + dr_w, src_grid_c + dc_w\n","                        if (tgt_grid_r, tgt_grid_c) in hcoords:\n","                            j = hcoords[(tgt_grid_r, tgt_grid_c)]\n","                            dst_pos = positions[j]\n","                            vec_ij = dst_pos - src_pos\n","                            dist = np.linalg.norm(vec_ij)\n","                            if dist < 1e-6 : continue\n","                            angle_ij_cartesian_rad = math.atan2(vec_ij[1], vec_ij[0])\n","                            wind_blowing_to_cartesian_rad = (math.pi/2 - wind_blowing_to_meteo_rad) % (2*math.pi)\n","                            wind_align_cos = math.cos(angle_ij_cartesian_rad - wind_blowing_to_cartesian_rad)\n","                            wind_strength_factor = np.clip(wind_speed / self.max_expected_wind_speed, 0, 1)\n","                            radius_mod_factor = 1.0 + self.wind_effect_on_radius_factor * wind_align_cos * wind_strength_factor\n","                            effective_dist_for_connection = dist / radius_mod_factor if radius_mod_factor > 1e-6 else dist * 1e6\n","                            if effective_dist_for_connection <= base_local_radius_grids * self.grid_size:\n","                                edge_index_list.append([i, j])\n","                                current_edge_attr = [dist, float(dc_w), float(dr_w), wind_align_cos, edge_type_local_wind]\n","                                edge_attr_list.append(current_edge_attr)\n","                                weight = self._calculate_edge_weight(dist, wind_align_cos, wind_speed, False, edge_type_local_wind)\n","                                edge_weights_list.append(weight)\n","\n","        if not edge_index_list:\n","            return np.empty((0, 2), dtype=np.int64), \\\n","                   np.empty((0, base_edge_attr_dim_no_globals + 1), dtype=np.float32), \\\n","                   np.empty(0, dtype=np.float32)\n","\n","        return np.array(edge_index_list, dtype=np.int64), \\\n","               np.array(edge_attr_list, dtype=np.float32), \\\n","               np.array(edge_weights_list, dtype=np.float32)\n","\n","    def _build_edges_topk_feature_similarity(self, node_features_local, positions,\n","                                             hourly_weather_params, solar_params):\n","        num_nodes = len(node_features_local)\n","        base_edge_attr_dim_no_globals = 4\n","        edge_type = EDGE_TYPE_SIMILARITY\n","\n","        if num_nodes == 0 or self.k_similarity <= 0:\n","            return np.empty((0, 2), dtype=np.int64), \\\n","                   np.empty((0, base_edge_attr_dim_no_globals + 1), dtype=np.float32), \\\n","                   np.empty(0, dtype=np.float32)\n","\n","        if num_nodes > 1 :\n","            mean_nf = np.mean(node_features_local, axis=0, keepdims=True)\n","            std_nf = np.std(node_features_local, axis=0, keepdims=True)\n","            node_features_normalized_for_knn = (node_features_local - mean_nf) / (std_nf + self.knn_epsilon)\n","        else:\n","            node_features_normalized_for_knn = node_features_local\n","\n","        dist_mat_feat = pairwise_distances(node_features_normalized_for_knn, node_features_normalized_for_knn, metric='euclidean')\n","\n","        edge_index_list, edge_attr_list, edge_weights_list = [], [], []\n","        wind_speed = hourly_weather_params['wind_speed_mps'] # Still needed for _calculate_edge_weight signature\n","        wind_blowing_to_meteo_rad = hourly_weather_params['wind_blowing_to_meteo_rad']\n","\n","        for i in range(num_nodes):\n","            dist_mat_feat[i, i] = 1e9\n","            actual_k = min(self.k_similarity, num_nodes - 1 if num_nodes > 1 else 0)\n","            if actual_k == 0 and num_nodes > 1 and self.k_similarity > 0: actual_k = 1\n","\n","            if actual_k > 0:\n","                topk_idx = np.argsort(dist_mat_feat[i])[:actual_k]\n","                src_pos = positions[i]\n","                for nbr_idx in topk_idx:\n","                    dst_pos = positions[nbr_idx]\n","                    dist = np.linalg.norm(src_pos - dst_pos)\n","                    vec_ij = dst_pos - src_pos\n","                    if np.linalg.norm(vec_ij) < 1e-6: continue\n","                    dx_grid = int(round(vec_ij[0] / self.grid_size))\n","                    dy_grid = int(round(vec_ij[1] / self.grid_size))\n","                    angle_ij_cartesian_rad = math.atan2(vec_ij[1], vec_ij[0])\n","                    wind_blowing_to_cartesian_rad = (math.pi/2 - wind_blowing_to_meteo_rad) % (2*math.pi)\n","                    wind_align_cos = math.cos(angle_ij_cartesian_rad - wind_blowing_to_cartesian_rad)\n","                    edge_index_list.append([i, nbr_idx])\n","                    current_edge_attr = [dist, float(dx_grid), float(dy_grid), wind_align_cos, edge_type]\n","                    edge_attr_list.append(current_edge_attr)\n","                    # Pass all params, but only dist_m and edge_type will be used by simplified weight calc\n","                    weight = self._calculate_edge_weight(dist, wind_align_cos, wind_speed, False, edge_type)\n","                    edge_weights_list.append(weight)\n","\n","        if not edge_index_list:\n","            return np.empty((0, 2), dtype=np.int64), \\\n","                   np.empty((0, base_edge_attr_dim_no_globals + 1), dtype=np.float32), \\\n","                   np.empty(0, dtype=np.float32)\n","        return np.array(edge_index_list, dtype=np.int64), \\\n","               np.array(edge_attr_list, dtype=np.float32), \\\n","               np.array(edge_weights_list, dtype=np.float32)\n","\n","    def _merge_undirected_edges(self, ei1, ea1, ew1, ei2, ea2, ew2):\n","        edge_attr_dim_with_type = 4 + 1\n","\n","        if ei1.size == 0:\n","            edge_index_comb, edge_attr_comb, edge_weights_comb = ei2, ea2, ew2\n","        elif ei2.size == 0:\n","            edge_index_comb, edge_attr_comb, edge_weights_comb = ei1, ea1, ew1\n","        else:\n","            edge_index_comb = np.concatenate([ei1, ei2], axis=0)\n","            edge_attr_comb = np.concatenate([ea1, ea2], axis=0)\n","            edge_weights_comb = np.concatenate([ew1, ew2], axis=0)\n","\n","        if edge_index_comb.shape[0] == 0:\n","            return np.empty((0,2), dtype=np.int64), \\\n","                   np.empty((0, edge_attr_dim_with_type), dtype=np.float32), \\\n","                   np.empty(0, dtype=np.float32)\n","\n","        unique_directed_edges = {}\n","        for idx in range(edge_index_comb.shape[0]):\n","            src, dst = edge_index_comb[idx, 0], edge_index_comb[idx, 1]\n","            attr = edge_attr_comb[idx]\n","            weight = edge_weights_comb[idx]\n","            if src == dst: continue\n","            if (src,dst) not in unique_directed_edges:\n","                unique_directed_edges[(src,dst)] = (attr, weight)\n","\n","        final_ei_list, final_ea_list, final_ew_list = [], [], []\n","        processed_undirected_pairs = set()\n","\n","        for (s, d), (attr_s_d, weight_s_d) in unique_directed_edges.items():\n","            u, v = min(s,d), max(s,d)\n","            if (u,v) in processed_undirected_pairs:\n","                continue\n","\n","            final_ei_list.append([s,d])\n","            final_ea_list.append(attr_s_d)\n","            final_ew_list.append(weight_s_d)\n","\n","            if (d,s) in unique_directed_edges:\n","                attr_d_s, weight_d_s = unique_directed_edges[(d,s)]\n","                final_ei_list.append([d,s])\n","                final_ea_list.append(attr_d_s)\n","                final_ew_list.append(weight_d_s)\n","            else:\n","                attr_d_s_created = attr_s_d.copy()\n","                attr_d_s_created[1] *= -1 # dx (index 1)\n","                attr_d_s_created[2] *= -1 # dy (index 2)\n","                attr_d_s_created[3] *= -1 # wind_align_cos (index 3)\n","                # Edge type (index 4) remains the same\n","                final_ei_list.append([d,s])\n","                final_ea_list.append(attr_d_s_created)\n","                final_ew_list.append(weight_s_d)\n","            processed_undirected_pairs.add((u,v))\n","\n","        if not final_ei_list:\n","            return np.empty((0,2), dtype=np.int64), \\\n","                   np.empty((0, edge_attr_dim_with_type), dtype=np.float32), \\\n","                   np.empty(0, dtype=np.float32)\n","\n","        return np.array(final_ei_list), np.array(final_ea_list), np.array(final_ew_list)\n","\n","\n","# ==================== 图增广模块 ===================\n","class GraphAugmentor:\n","    def __init__(\n","        self,\n","        add_struct_features=False,\n","        add_neighbor_agg=False,\n","        add_edge_diff=False,\n","        use_laplacian_pe=False,\n","        lap_pe_dim=4,\n","        normalization='sym',\n","        max_iter=2000\n","    ):\n","        self.add_struct_features = add_struct_features\n","        self.add_neighbor_agg = add_neighbor_agg\n","        self.add_edge_diff = add_edge_diff\n","        self.use_laplacian_pe = use_laplacian_pe\n","        self.lap_pe_dim = lap_pe_dim\n","        self.normalization = normalization\n","        self.max_iter = max_iter\n","        if add_neighbor_agg and not ('scatter_mean' in globals() or 'torch_scatter' in globals()):\n","            raise ImportError(\"torch_scatter.scatter_mean is required for add_neighbor_agg=True. Please install torch-scatter.\")\n","\n","\n","    def augment_static(self, data):\n","        if self.add_struct_features:\n","            self._add_structural_features(data)\n","        if self.add_neighbor_agg:\n","            self._add_neighbor_mean_features(data)\n","        if self.add_edge_diff:\n","            self._add_edge_diff(data)\n","        if self.use_laplacian_pe:\n","            self._add_laplacian_positional_encoding(data)\n","        return data\n","\n","    def _add_structural_features(self, data):\n","        if data.num_nodes == 0 or data.num_edges == 0 : return\n","        try:\n","            G = to_networkx(data, to_undirected=True)\n","            deg_dict = dict(G.degree())\n","            clust_dict = nx.clustering(G)\n","            pr_dict = nx.pagerank(G, alpha=0.85, max_iter=100, tol=1.e-04)\n","\n","            deg_list = [deg_dict.get(i, 0) for i in range(data.num_nodes)]\n","            clust_list = [clust_dict.get(i, 0.0) for i in range(data.num_nodes)]\n","            pr_list = [pr_dict.get(i, 0.0) for i in range(data.num_nodes)]\n","\n","            deg_tensor = torch.tensor(deg_list, dtype=torch.float, device=data.x.device).unsqueeze(1)\n","            clust_tensor = torch.tensor(clust_list, dtype=torch.float, device=data.x.device).unsqueeze(1)\n","            pr_tensor = torch.tensor(pr_list, dtype=torch.float, device=data.x.device).unsqueeze(1)\n","            data.x = torch.cat([data.x, deg_tensor, clust_tensor, pr_tensor], dim=1)\n","        except Exception as e:\n","            print(f\"Error in _add_structural_features: {e}\")\n","\n","\n","    def _add_neighbor_mean_features(self, data):\n","        if data.num_nodes == 0 or data.num_edges == 0 : return\n","        try:\n","            row, col = data.edge_index\n","            x_mean = scatter_mean(data.x[col].float(), row, dim=0, dim_size=data.num_nodes)\n","            data.x = torch.cat([data.x, x_mean], dim=1)\n","        except Exception as e:\n","            print(f\"Error in _add_neighbor_mean_features: {e}\")\n","\n","\n","    def _add_edge_diff(self, data):\n","        if data.num_nodes == 0 or data.num_edges == 0 : return\n","        if not hasattr(data, 'edge_attr') or data.edge_attr is None:\n","            print(\"Warning: add_edge_diff called but data.edge_attr is None. Skipping.\")\n","            return\n","\n","        src_nodes_x = data.x[data.edge_index[0]].float()\n","        dst_nodes_x = data.x[data.edge_index[1]].float()\n","        feat_diffs = src_nodes_x - dst_nodes_x\n","\n","        data.edge_attr = data.edge_attr.float()\n","        data.edge_attr = torch.cat([data.edge_attr, feat_diffs], dim=1)\n","\n","\n","    def _add_laplacian_positional_encoding(self, data, normalization='sym', edge_weight=None, max_iter=2000):\n","        if data.num_nodes == 0 or data.num_edges == 0 or self.lap_pe_dim <=0 : return\n","        try:\n","            G_nx = to_networkx(data, to_undirected=True, remove_self_loops=True)\n","            L_sp = nx.laplacian_matrix(G_nx).astype(float)\n","            N = data.num_nodes\n","            k = min(self.lap_pe_dim, N - 2 if N > 1 else 0)\n","            if k <= 0: return\n","\n","            eigen_vals, eigen_vecs = spla.eigsh(\n","                L_sp, k=k, which='SM', tol=1e-3,\n","                maxiter=max_iter, return_eigenvectors=True\n","            )\n","            idx = np.argsort(eigen_vals)\n","            eigen_vecs = eigen_vecs[:, idx]\n","            lap_pe_tensor = torch.from_numpy(eigen_vecs).float().to(data.x.device)\n","            data.x = torch.cat([data.x, lap_pe_tensor], dim=1)\n","        except Exception as e:\n","            print(f\"Error in _add_laplacian_positional_encoding: {e}\")\n","\n","# ==================== 辅助函数 ===================\n","def compute_global_maxes(input_dir):\n","    input_files = sorted(Path(input_dir).glob(\"Input_*.npy\"))\n","    if not input_files: return 1.0, 1.0\n","    global_tree_max = -np.inf\n","    global_building_max = -np.inf\n","    has_valid_tree_max = False\n","    has_valid_bldg_max = False\n","    for file_path in input_files:\n","        data = np.load(file_path).astype(np.float32)\n","        if data.ndim == 3 and data.shape[2] >= 1 and data[:,:,0].size > 0 :\n","            current_tree_max = data[:, :, 0].max()\n","            if not np.isinf(current_tree_max) and not np.isnan(current_tree_max):\n","                global_tree_max = max(global_tree_max, current_tree_max)\n","                has_valid_tree_max = True\n","        if data.ndim == 3 and data.shape[2] >= 3 and data[:,:,2].size > 0:\n","            current_bldg_max = data[:, :, 2].max()\n","            if not np.isinf(current_bldg_max) and not np.isnan(current_bldg_max):\n","                global_building_max = max(global_building_max, current_bldg_max)\n","                has_valid_bldg_max = True\n","    final_tree_max = global_tree_max if has_valid_tree_max and global_tree_max > 0 else 1.0\n","    final_bldg_max = global_building_max if has_valid_bldg_max and global_building_max > 0 else 1.0\n","    return final_tree_max, final_bldg_max\n","\n","\n","def generate_data_report(graph, save_report=False):\n","    report = [\"=\"*40 + \"\\n图数据结构分析报告 (单小时)\\n\" + \"=\"*40]\n","    report.append(f\"\\n[文件ID (如有)]: {getattr(graph, 'file_id', 'N/A')}\")\n","    report.append(f\"[小时 (如有)]: {getattr(graph, 'hour_of_day', 'N/A')}\")\n","    report.append(f\"\\n[维度信息]\")\n","    report.append(f\"节点数量: {graph.num_nodes}\")\n","    report.append(f\"边数量: {graph.num_edges}\")\n","    report.append(f\"节点特征维度: {graph.x.shape}\")\n","    edge_attr_shape_str = 'N/A'\n","    if hasattr(graph, 'edge_attr') and graph.edge_attr is not None:\n","        edge_attr_shape_str = str(graph.edge_attr.shape)\n","        if graph.edge_attr.shape[1] == 6: # 4 local physical + 1 type + 1 weight\n","            report.append(f\"  (边特征包含: 4局部物理 + 1类型 + 1权重)\")\n","        elif graph.edge_attr.shape[1] == 5:\n","             report.append(f\"  (边特征包含: 4局部物理 + 1类型)\")\n","\n","    report.append(f\"边特征维度 (edge_attr): {edge_attr_shape_str}\")\n","    report.append(f\"边权重维度 (edge_weight): {graph.edge_weight.shape if hasattr(graph, 'edge_weight') and graph.edge_weight is not None else 'N/A'}\")\n","    report.append(f\"目标值维度: {graph.y.shape}\")\n","\n","    report.append(\"\\n[节点特征X (前5行样本)]:\\n\" + str(graph.x[:5].numpy()))\n","    if hasattr(graph, 'edge_attr') and graph.edge_attr is not None and graph.num_edges > 0:\n","        report.append(\"\\n[边特征EA (前5行样本)]:\\n\" + str(graph.edge_attr[:5].numpy()))\n","        if graph.edge_attr.shape[1] >= 5:\n","            edge_types_sample = graph.edge_attr[:min(5, graph.num_edges), 4].numpy()\n","            report.append(f\"  边类型 (前{len(edge_types_sample)}条边, 第5列): {edge_types_sample}\")\n","        if graph.edge_attr.shape[1] >= 6:\n","            edge_weights_in_attr_sample = graph.edge_attr[:min(5, graph.num_edges), 5].numpy()\n","            report.append(f\"  边权重 (来自边特征第6列, 前{len(edge_weights_in_attr_sample)}条): {edge_weights_in_attr_sample}\")\n","\n","    if hasattr(graph, 'edge_weight') and graph.edge_weight is not None and graph.num_edges > 0:\n","        report.append(\"\\n[独立边权重EW (前5行样本)]:\\n\" + str(graph.edge_weight[:5].numpy()))\n","        report.append(f\"  独立边权重统计: min={graph.edge_weight.min().item():.3f}, max={graph.edge_weight.max().item():.3f}, mean={graph.edge_weight.mean().item():.3f}\")\n","\n","    # --- 新增：专门统计阴影边的权重 ---\n","    report.append(\"\\n[阴影边 (EDGE_TYPE_SHADOW) 权重统计]\")\n","    if hasattr(graph, 'edge_attr') and graph.edge_attr is not None and \\\n","       hasattr(graph, 'edge_weight') and graph.edge_weight is not None and \\\n","       graph.num_edges > 0 and graph.edge_attr.shape[1] >= 5: # 需要至少5列来获取类型\n","\n","        try:\n","            # 假设 EDGE_TYPE_SHADOW 是全局定义的常量 (例如 1.0)\n","            # 边类型在 edge_attr 的第5列 (索引4)\n","            edge_types = graph.edge_attr[:, 4]\n","            shadow_edge_mask = (edge_types == EDGE_TYPE_SHADOW) # EDGE_TYPE_SHADOW = 1.0\n","\n","            num_shadow_edges = shadow_edge_mask.sum().item()\n","            report.append(f\"  数量: {num_shadow_edges}\")\n","\n","            if num_shadow_edges > 0:\n","                shadow_weights = graph.edge_weight[shadow_edge_mask]\n","                report.append(f\"  Min: {shadow_weights.min().item():.4f}\")\n","                report.append(f\"  Max: {shadow_weights.max().item():.4f}\")\n","                report.append(f\"  Mean: {shadow_weights.mean().item():.4f}\")\n","                report.append(f\"  Std: {shadow_weights.std().item():.4f}\")\n","            else:\n","                report.append(\"  未找到阴影边。\")\n","        except IndexError:\n","            report.append(\"  错误：无法从edge_attr中提取边类型（维度不足）。\")\n","        except Exception as e:\n","            report.append(f\"  提取阴影边权重时出错: {e}\")\n","    else:\n","        report.append(\"  无边或无edge_attr/edge_weight用于统计阴影边。\")\n","    # --- 阴影边权重统计结束 ---\n","\n","    # --- 新增：专门统计树木活动边的权重 ---\n","    report.append(\"\\n[树木活动边 (EDGE_TYPE_TREE_ACTIVITY=0.0) 权重统计]\") # 假设 EDGE_TYPE_TREE_ACTIVITY = 0.0\n","    if hasattr(graph, 'edge_attr') and graph.edge_attr is not None and \\\n","       hasattr(graph, 'edge_weight') and graph.edge_weight is not None and \\\n","       graph.num_edges > 0 and graph.edge_attr.shape[1] >= 5: # 需要至少5列来获取类型\n","\n","        try:\n","            edge_types = graph.edge_attr[:, 4]\n","            tree_activity_edge_mask = (edge_types == EDGE_TYPE_TREE_ACTIVITY) # 使用定义好的常量或直接用值 0.0\n","\n","            num_tree_activity_edges = tree_activity_edge_mask.sum().item()\n","            report.append(f\"  数量: {num_tree_activity_edges}\")\n","\n","            if num_tree_activity_edges > 0:\n","                tree_activity_weights = graph.edge_weight[tree_activity_edge_mask]\n","                report.append(f\"  Min: {tree_activity_weights.min().item():.4f}\")\n","                report.append(f\"  Max: {tree_activity_weights.max().item():.4f}\")\n","                report.append(f\"  Mean: {tree_activity_weights.mean().item():.4f}\")\n","                report.append(f\"  Std: {tree_activity_weights.std().item():.4f}\")\n","            else:\n","                report.append(\"  未找到树木活动边。\")\n","        except IndexError:\n","            report.append(\"  错误：无法从edge_attr中提取边类型（维度不足）。\")\n","        except Exception as e:\n","            report.append(f\"  提取树木活动边权重时出错: {e}\")\n","    else:\n","        report.append(\"  无边或无edge_attr/edge_weight用于统计树木活动边。\")\n","    # --- 树木活动边权重统计结束 ---\n","\n","    report.append(\"\\n[目标值Y (前5行样本)]:\\n\" + str(graph.y[:5].numpy()))\n","\n","    if hasattr(graph, 'graph_global_env_features') and graph.graph_global_env_features is not None:\n","        report.append(\"\\n[图级别全局环境特征 (7维)]:\\n\" + str(graph.graph_global_env_features.numpy()))\n","\n","    if hasattr(graph, 'hourly_weather') and graph.hourly_weather is not None:\n","        report.append(\"\\n[原始小时气象参数]:\\n\" + str(graph.hourly_weather.numpy()))\n","    if hasattr(graph, 'solar_position') and graph.solar_position is not None:\n","        report.append(\"\\n[原始太阳位置参数]:\\n\" + str(graph.solar_position.numpy()))\n","    final_report = \"\\n\".join(report)\n","    print(final_report)\n","\n","def verify_edge_structure(graph, grid_size=4, sample_size=10):\n","    if not hasattr(graph, 'edge_attr') or graph.edge_attr is None or graph.edge_attr.size(0) == 0 or graph.edge_attr.size(1) < 3:\n","        print(\"[verify_edge_structure] 警告：edge_attr 列数不足 (<3) 或无边，无法验证 (dist, dx, dy)\")\n","        return\n","\n","    edge_attrs_np = graph.edge_attr.cpu().numpy()\n","    edge_index_np = graph.edge_index.cpu().numpy()\n","    pos_np = graph.pos.cpu().numpy()\n","\n","    dist_all = edge_attrs_np[:, 0]\n","    print(f\"\\n[verify_edge_structure] 边距离统计 (来自edge_attr[:,0]): min={dist_all.min():.2f}, max={dist_all.max():.2f}, mean={dist_all.mean():.2f}\")\n","    if np.any(dist_all < 0): print(\"   [警告] 发现负距离！\")\n","\n","    num_edges_to_sample = min(sample_size, graph.num_edges)\n","    if num_edges_to_sample == 0:\n","        print(\"   无边可供抽样检查。\")\n","        return\n","\n","    sampled_eids = np.random.choice(graph.num_edges, num_edges_to_sample, replace=False)\n","    print(f\"\\n   抽样 {num_edges_to_sample} 条边进行 (dist, dx, dy) 对比:\")\n","    for i, eid in enumerate(sampled_eids, 1):\n","        src_idx, dst_idx = edge_index_np[0, eid], edge_index_np[1, eid]\n","        dist_stored = edge_attrs_np[eid, 0]\n","        dx_grid_stored = edge_attrs_np[eid, 1]\n","        dy_grid_stored = edge_attrs_np[eid, 2]\n","        pos_src, pos_dst = pos_np[src_idx], pos_np[dst_idx]\n","        dist_calc = np.linalg.norm(pos_dst - pos_src)\n","        dx_calc_m = pos_dst[0] - pos_src[0]\n","        dy_calc_m = pos_dst[1] - pos_src[1]\n","        dx_grid_calc = dx_calc_m / grid_size\n","        dy_grid_calc = dy_calc_m / grid_size\n","        print(f\"   [{i}] EdgeID={eid} ({src_idx}->{dst_idx})\")\n","        print(f\"     存储: dist={dist_stored:.2f}, dx_g={dx_grid_stored:.2f}, dy_g={dy_grid_stored:.2f}\")\n","        print(f\"     计算: dist={dist_calc:.2f}, dx_g={dx_grid_calc:.2f}, dy_g={dy_grid_calc:.2f}\")\n","        if abs(dist_stored-dist_calc) > 1e-1 or abs(dx_grid_stored-dx_grid_calc) > 0.6 or abs(dy_grid_stored-dy_grid_calc) > 0.6 :\n","            print(f\"     [警告] 差异较大!\")\n","        else:\n","            print(f\"     [OK]\")\n","\n","def generate_sequence_y_report(graph_sequence, sequence_index=0, num_y_samples=5):\n","    \"\"\"\n","    为单个图序列中的每个图的 y 值生成报告。\n","    \"\"\"\n","    if not graph_sequence:\n","        print(f\"序列 {sequence_index} 为空，无法生成y值报告。\")\n","        return\n","\n","    report_lines = [\n","        f\"\\n{'='*25} Y 值详细报告: 序列 {sequence_index} (第一个成功处理的空间窗口) {'='*25}\",\n","        f\"序列中图的数量 (小时数): {len(graph_sequence)}\"\n","    ]\n","\n","    first_graph_for_ids = None\n","    for g in graph_sequence: # 找到第一个非None的图来获取ID信息\n","        if g is not None:\n","            first_graph_for_ids = g\n","            break\n","\n","    if first_graph_for_ids:\n","        report_lines.append(f\"文件ID (来自序列首图): {getattr(first_graph_for_ids, 'file_id', 'N/A')}\")\n","        report_lines.append(f\"窗口索引 (来自序列首图): {getattr(first_graph_for_ids, 'window_index', 'N/A')}\")\n","    else:\n","        report_lines.append(\"警告: 序列中所有图均为None，无法获取文件ID或窗口索引。\")\n","\n","\n","    for i, graph_data in enumerate(graph_sequence):\n","        if graph_data is None:\n","            report_lines.append(f\"\\n--- [序列内索引 {i}] 图数据: None ---\")\n","            continue\n","\n","        actual_hour = getattr(graph_data, 'hour_of_day', 'N/A')\n","        hour_in_seq_idx = getattr(graph_data, 'hour_index_in_sequence', i) # 应该与 i 一致\n","\n","        report_lines.append(f\"\\n--- [序列内索引 {hour_in_seq_idx}] 实际小时: {actual_hour if actual_hour != 'N/A' else '(未知)'}:00 ---\")\n","\n","        y_tensor = graph_data.y\n","        if y_tensor is None:\n","            report_lines.append(\"  y 值: None\")\n","        else:\n","            # 将y张量展平以便统计，即使它原本是 (N, 1)，展平后不影响统计纯数值\n","            y_np = y_tensor.cpu().numpy().flatten()\n","            num_elements_in_y = len(y_np) # y中元素的总数，通常等于节点数\n","            report_lines.append(f\"  y 原始张量形状: {list(y_tensor.shape)}\")\n","            report_lines.append(f\"  y 中元素数量 (通常为节点数): {num_elements_in_y}\")\n","\n","            if num_elements_in_y > 0:\n","                nan_count = np.sum(np.isnan(y_np)) # 使用 np.sum(np.isnan(...)) 更准确\n","                non_nan_y = y_np[~np.isnan(y_np)]\n","\n","                report_lines.append(f\"  y 中 NaN 值数量: {nan_count}\")\n","\n","                if nan_count == num_elements_in_y:\n","                    report_lines.append(\"  y 值统计: 全部为 NaN\")\n","                elif non_nan_y.size > 0 : # 确保有非NaN值才进行统计\n","                    report_lines.append(f\"  y 值统计 (非NaN部分): Min={np.min(non_nan_y):.4f}, Max={np.max(non_nan_y):.4f}, Mean={np.mean(non_nan_y):.4f}, Std={np.std(non_nan_y):.4f}\")\n","\n","                    # 从原始y_np中抽样，这样可以看到NaN值（如果存在并被抽到）\n","                    samples_to_show = min(num_y_samples, num_elements_in_y)\n","                    # 确保即使元素少于samples_to_show也能正确运行\n","                    if num_elements_in_y <= samples_to_show:\n","                        sampled_indices = np.arange(num_elements_in_y)\n","                    else:\n","                        sampled_indices = np.random.choice(num_elements_in_y, samples_to_show, replace=False)\n","\n","                    sampled_values = y_np[sampled_indices]\n","                    report_lines.append(f\"  y 值随机样本 ({len(sampled_values)}个): {sampled_values}\")\n","                elif nan_count > 0 and non_nan_y.size == 0 : # 逻辑上这个分支不应该在 nan_count != num_elements_in_y 时出现\n","                    report_lines.append(\"  y 值统计: 所有值均为 NaN (与 non_nan_y.size == 0 一致)\")\n","                else: # num_elements_in_y > 0 and nan_count == 0 and non_nan_y.size == 0 (不应该发生)\n","                     report_lines.append(\"  y 值: 状态异常 (例如，非NaN数组为空但NaN计数为0)\")\n","            else: # num_elements_in_y == 0\n","                report_lines.append(\"  y 值: 空 (y中无元素/节点数为0)\")\n","\n","    report_lines.append(f\"\\n{'='*70}\")\n","    print(\"\\n\".join(report_lines))\n","\n","# 在 process_12_hour_sequences 函数定义处添加新的参数\n","def process_12_hour_sequences(\n","    input_dir_str: str,\n","    output_dir_str: str,\n","    csv_path_str: str,\n","    target_date_tuple: tuple,\n","    start_hour_of_day_sequence: int,\n","    num_hours_in_sequence: int,\n","    output_npy_effective_start_hour: int, # 新增：Output.npy中数据对应的起始小时\n","    output_npy_fill_value_for_missing_y: float = float('nan'), # 新增：缺失y的填充值，默认为NaN\n","    window_size: int = 50,\n","    stride: int = 40,\n","    target_attr_index_in_output: int = 5,\n","    graph_constructor_params: dict = None,\n","    graph_augmentor_instance=None\n","):\n","    input_dir = Path(input_dir_str)\n","    output_dir = Path(output_dir_str)\n","    input_files = sorted(input_dir.glob(\"Input_*.npy\"))\n","\n","    if not input_files:\n","        print(f\"错误: 在 '{input_dir}' 未找到任何 Input_*.npy 文件。\")\n","        return []\n","\n","    # --- 全局初始化 (执行一次) ---\n","    global_tree_max, global_building_max = compute_global_maxes(str(input_dir))\n","    print(f\"全局最大树高: {global_tree_max}, 全局最大建筑高度: {global_building_max}\")\n","\n","    sg_latitude, sg_longitude = 1.3521, 103.8198 # Singapore coordinates\n","    solar_calc = SolarCalculator(latitude=sg_latitude, longitude=sg_longitude, timezone_str='Asia/Singapore')\n","    weather_parser = CSVWeatherParser(csv_path=csv_path_str)\n","\n","    year, month, day = target_date_tuple\n","\n","    # 初始化 GraphConstructor (使用传入的参数)\n","    # 将 global_tree_max 和 global_building_max 添加到参数字典中\n","    gc_params_with_globals = graph_constructor_params.copy()\n","    gc_params_with_globals['global_tree_max_val'] = global_tree_max\n","    gc_params_with_globals['global_building_max_val'] = global_building_max\n","    gc_params_with_globals['target_attr_index'] = target_attr_index_in_output # Ensure this is passed\n","\n","    graph_builder = GraphConstructor(**gc_params_with_globals)\n","\n","    all_window_sequences = [] # 外层列表: 每个元素是一个窗口的12小时图序列\n","\n","    # --- 外层循环: 遍历输入文件 ---\n","    for input_path in input_files:\n","        match = re.search(r\"Input_(\\d+).npy\", input_path.name)\n","        if not match:\n","            print(f\"跳过不匹配的文件名: {input_path.name}\")\n","            continue\n","        file_id = match.group(1)\n","        output_path_npy = output_dir / f\"Output_{file_id}.npy\"\n","\n","        if not output_path_npy.exists():\n","            print(f\"跳过 {input_path.name}: 缺少对应 Output_{file_id}.npy\")\n","            continue\n","\n","        print(f\"\\n=== 开始处理文件对 {file_id} 的所有12小时序列 ===\")\n","        try:\n","            preprocessor = ClimateDataPreprocessor(\n","                input_path=str(input_path),\n","                output_path=str(output_path_npy),\n","                window_size=window_size,\n","                stride=stride,\n","                global_tree_max=global_tree_max,\n","                global_building_max=global_building_max\n","            )\n","            input_windows, output_windows = preprocessor.process()\n","\n","            # 从 output_windows (即 out_win_all_hrs 的来源) 获取 .npy 文件中的小时数\n","            # output_windows 的形状是 (num_windows, num_vars_output, win_h, win_w, hours_in_npy)\n","            # 但 preprocessor.process() 返回的是 (num_windows, win_h, win_w, num_base_features) for input\n","            # 和 (num_windows, num_vars_output, win_h, win_w, hours_in_output_npy) for output\n","            # 因此，我们需要从 preprocessor.output_data 来获取 hours_in_output_npy\n","            if preprocessor.output_data.ndim == 4 and preprocessor.output_data.shape[3] > 0:\n","                 hours_in_output_npy = preprocessor.output_data.shape[3]\n","            else:\n","                 print(f\"警告: 无法从 Output_{file_id}.npy 的形状确定小时数，将假定为 {num_hours_in_sequence}\")\n","                 hours_in_output_npy = num_hours_in_sequence\n","\n","            # --- 中层循环: 遍历该文件的所有空间窗口 ---\n","            for window_idx, (inp_win_base_feats, out_win_all_hrs) in enumerate(zip(input_windows, output_windows)):\n","                current_window_hourly_graphs = []\n","                print(f\"  -- 处理文件 {file_id}, 窗口索引 {window_idx} --\")\n","\n","                # --- 内层循环: 遍历序列中的每个小时 ---\n","                for hour_offset in range(num_hours_in_sequence):\n","                    actual_hour_of_day = start_hour_of_day_sequence + hour_offset\n","\n","                    # 确定用于从 out_win_all_hrs 提取 y 值的索引\n","                    # 以及判断当前 actual_hour_of_day 的 y 值是否有效\n","                    y_data_slice_index = actual_hour_of_day - output_npy_effective_start_hour\n","                    y_is_valid_for_this_hour = False\n","                    target_hour_index_for_graph_build = 0 # 默认为0，如果y无效则此索引无实际意义\n","\n","                    if 0 <= y_data_slice_index < hours_in_output_npy:\n","                        y_is_valid_for_this_hour = True\n","                        target_hour_index_for_graph_build = y_data_slice_index\n","                    # else y_data_slice_index < 0 (e.g. 7 AM < 8 AM) or y_data_slice_index >= hours_in_output_npy (e.g. 8 PM > 7 PM if npy is 8-19)\n","\n","                    # 获取当前小时的太阳和天气参数 (这部分逻辑不变)\n","                    try:\n","                        current_solar_params = solar_calc.get_solar_position(year, month, day, actual_hour_of_day)\n","                        current_hourly_weather_params = weather_parser.get_hourly_data(month, day, actual_hour_of_day)\n","                    except Exception as e:\n","                        print(f\"    错误: 无法获取 {month}-{day} {actual_hour_of_day}:00 的太阳/气象数据: {e}. 跳过此小时。\")\n","                        # current_window_hourly_graphs.append(None) # Or handle as needed\n","                        print(f\"    由于数据获取失败，跳过文件 {file_id}, 窗口 {window_idx}, 小时偏移 {hour_offset} 的图构建。\")\n","                        continue\n","\n","                    # 构建当前小时的图\n","                    try:\n","                        graph = graph_builder.build_graph(\n","                            inp_win_base_feats,\n","                            out_win_all_hrs,\n","                            current_hourly_weather_params,\n","                            current_solar_params,\n","                            # 使用计算得到的 target_hour_index_for_graph_build\n","                            target_hour_index_in_day=target_hour_index_for_graph_build\n","                        )\n","                        graph.file_id = file_id\n","                        graph.window_index = window_idx\n","                        graph.hour_of_day = actual_hour_of_day\n","                        graph.hour_index_in_sequence = hour_offset\n","\n","                        # 如果当前小时的 y 值无效，则用指定值填充\n","                        if not y_is_valid_for_this_hour:\n","                            if graph.y is not None: # 确保 y 属性存在\n","                                fill_value_tensor = torch.full_like(graph.y, output_npy_fill_value_for_missing_y)\n","                                graph.y = fill_value_tensor\n","                                # print(f\"    提示: 文件 {file_id}, 窗口 {window_idx}, 实际小时 {actual_hour_of_day}:00 的 y 值被填充为 {output_npy_fill_value_for_missing_y}\")\n","\n","                        if graph_augmentor_instance:\n","                            graph = graph_augmentor_instance.augment_static(graph)\n","\n","                        current_window_hourly_graphs.append(graph)\n","\n","                    except Exception as graph_err:\n","                        print(f\"    构建图失败 (文件:{file_id}, 窗口索引:{window_idx}, 小时偏移:{hour_offset}, 实际小时:{actual_hour_of_day}): {graph_err}\")\n","                        import traceback\n","                        traceback.print_exc()\n","                        # current_window_hourly_graphs.append(None)\n","\n","                if len(current_window_hourly_graphs) == num_hours_in_sequence:\n","                    all_window_sequences.append(current_window_hourly_graphs)\n","                elif current_window_hourly_graphs:\n","                     print(f\"  警告: 文件 {file_id}, 窗口 {window_idx} 的序列不完整 (仅 {len(current_window_hourly_graphs)}/{num_hours_in_sequence} 个图)，已跳过此窗口序列。\")\n","\n","        except Exception as e:\n","            print(f\"处理文件对 {file_id} 时发生严重错误: {e}\")\n","            import traceback\n","            traceback.print_exc()\n","            continue\n","\n","    print(f\"\\n处理完成，共生成 {len(all_window_sequences)} 个窗口的{num_hours_in_sequence}小时图序列。\")\n","    if all_window_sequences and all_window_sequences[0]:\n","        print(\"\\n=== 抽样检查首个窗口的首个图 ===\")\n","        # Ensure all_window_sequences[0] is not empty before accessing all_window_sequences[0][0]\n","        if all_window_sequences[0][0] is not None:\n","             generate_data_report(all_window_sequences[0][0]) # Report for the first hour of the first window\n","             verify_edge_structure(all_window_sequences[0][0], grid_size=graph_builder.grid_size)\n","        else:\n","            print(\"抽样检查失败：首个窗口的首个图未能成功构建。\")\n","\n","    return all_window_sequences\n","\n","# ==================== 主函数 (12小时序列生成) ===================\n","def main_generate_12_hour_data(): # <<<< RENAMED\n","    base_drive_path = Path(\"/content/drive/MyDrive/Colab Notebooks/Graph Data Process\") # 请确保路径正确\n","    input_dir = base_drive_path / \"Input\"\n","    output_dir = base_drive_path / \"Output\"\n","    csv_path = base_drive_path / \"SGP_SINGAPORE-CHANGI-IAP_486980S_23EPW.csv\"\n","    # save_dir = base_drive_path / \"Result\" / \"SingleHourTest_Weight\" # 旧的\n","    save_dir = base_drive_path / \"Result\" / \"Sequential_12Hour_Data\" # <<<< 新的保存目录名\n","    save_dir.mkdir(parents=True, exist_ok=True)\n","\n","    # --- 时间参数 ---\n","    TARGET_YEAR = 2023\n","    TARGET_MONTH = 5\n","    TARGET_DAY = 3\n","    # 定义12小时序列的起始小时 (例如，8点对应气象数据中的8)\n","    # output_window_all_hours 的最后一维 (12) 对应这12个小时\n","    # 例如，如果 output NPY 的12个小时是从 8:00 到 19:00\n","    START_HOUR_OF_DAY_IN_SEQUENCE = 7\n","    NUM_HOURS_IN_SEQUENCE = 13\n","\n","    # --- 新增参数：指明 Output.npy 文件中数据实际对应的起始小时 ---\n","    # 假设您的 Output_*.npy 文件中的第0个时间片对应的是早上8点的数据\n","    OUTPUT_NPY_EFFECTIVE_START_HOUR = 8\n","    # --- 新增参数：指定当y数据缺失时（如7点对比8点）的填充值 ---\n","    # float('nan') 表示用NaN填充，如果想用0，则改为 0.0\n","    #OUTPUT_NPY_FILL_VALUE = float('nan')\n","    OUTPUT_NPY_FILL_VALUE = 0.0 # 如果希望用0填充\n","\n","    # --- GraphConstructor 参数 ---\n","    # 这些参数将通过字典传递给 process_12_hour_sequences\n","    graph_constructor_config = {\n","        'grid_size': 4, # Default, but can be set\n","        'k_similarity': 8,\n","        # 'target_attr_index' will be set by process_12_hour_sequences\n","        'base_building_shadow_radius_max_grids': 15,\n","        'base_tree_shadow_radius_max_grids': 5,\n","        'base_tree_activity_radius_max_grids': 5, # Example: t_rmax_activity_grids\n","        'base_edge_weight': 1.0,\n","        'shadow_influence_weight_factor': 1.5, # Unused currently\n","        'wind_alignment_weight_factor': 0.5,   # Unused currently\n","        'distance_decay_factor_per_grid': 0.01,\n","        'similarity_dist_decay_factor_per_grid': 0.005,\n","        'actual_shadow_boost_factor': 1.2,\n","        'tree_activity_height_influence_factor': 0.2, # Your chosen value\n","        'shadow_angular_width_deg': 25.0,\n","        'knn_node_feature_normalization_epsilon': 1e-5,\n","        'internal_n8_weight': 0.1 # Unused currently\n","        # global_tree_max_val and global_building_max_val will be added inside processing function\n","    }\n","\n","    # --- 其他参数 ---\n","    target_variable_idx_in_output_file = 5 # 例如，如果目标变量在Output.npy的第6个变量（索引5）\n","    data_window_size = 50\n","    data_stride = 40\n","\n","    augmentor = GraphAugmentor(add_neighbor_agg=True, add_edge_diff=False) # Or None\n","\n","    print(f\"\\n--- 开始为 {TARGET_YEAR}-{TARGET_MONTH}-{TARGET_DAY} 生成 {NUM_HOURS_IN_SEQUENCE} 小时图序列数据 ---\")\n","    print(f\"序列起始小时 (真实小时): {START_HOUR_OF_DAY_IN_SEQUENCE}\")\n","    print(f\"GraphConstructor 参数: {graph_constructor_config}\")\n","\n","    all_sequences = process_12_hour_sequences(\n","        input_dir_str=str(input_dir),\n","        output_dir_str=str(output_dir),\n","        csv_path_str=str(csv_path),\n","        target_date_tuple=(TARGET_YEAR, TARGET_MONTH, TARGET_DAY),\n","        start_hour_of_day_sequence=START_HOUR_OF_DAY_IN_SEQUENCE,\n","        num_hours_in_sequence=NUM_HOURS_IN_SEQUENCE,\n","        output_npy_effective_start_hour=OUTPUT_NPY_EFFECTIVE_START_HOUR, # 传递新参数\n","        output_npy_fill_value_for_missing_y=OUTPUT_NPY_FILL_VALUE,   # 传递新参数\n","        window_size=data_window_size,\n","        stride=data_stride,\n","        target_attr_index_in_output=target_variable_idx_in_output_file,\n","        graph_constructor_params=graph_constructor_config,\n","        graph_augmentor_instance=augmentor\n","    )\n","\n","    if all_sequences:\n","        save_name = (\n","            f\"graph_seq_{TARGET_YEAR}{TARGET_MONTH:02d}{TARGET_DAY:02d}_\"\n","            f\"SeqH{START_HOUR_OF_DAY_IN_SEQUENCE}to{START_HOUR_OF_DAY_IN_SEQUENCE+NUM_HOURS_IN_SEQUENCE-1}_\"\n","            f\"NpyH{OUTPUT_NPY_EFFECTIVE_START_HOUR}fill{str(OUTPUT_NPY_FILL_VALUE)}.pkl\"\n","        )\n","        save_path = save_dir / save_name\n","        with open(save_path, \"wb\") as f:\n","            pickle.dump(all_sequences, f)\n","        print(f\"\\n[已保存] {NUM_HOURS_IN_SEQUENCE}小时图序列数据 => {save_path}\")\n","\n","        # --- 新增：生成并打印第一个完整序列的 Y 值报告 ---\n","        print(\"\\n\\n=== 开始生成Y值详细报告 (针对第一个成功处理的空间窗口的完整时间序列) ===\")\n","        # all_sequences 是一个列表的列表，外层列表代表不同的空间窗口滑动的结果\n","        # 内层列表代表一个空间窗口随时间变化的图序列\n","        # 我们报告第一个成功处理的空间窗口的整个时间序列\n","        first_complete_sequence_found = False\n","        for seq_idx, window_sequence in enumerate(all_sequences):\n","            if window_sequence and all(graph is not None for graph in window_sequence): # 确保序列非空且内部图都存在\n","                generate_sequence_y_report(window_sequence, sequence_index=seq_idx)\n","                first_complete_sequence_found = True\n","                break # 只报告第一个找到的完整序列\n","            elif window_sequence: # 序列存在，但可能包含None\n","                # 可选：报告不完整的序列信息\n","                num_valid_graphs = sum(1 for g in window_sequence if g is not None)\n","                print(f\"提示: 序列 {seq_idx} 不完整或包含None图 (有效图: {num_valid_graphs}/{len(window_sequence)})，跳过其Y值报告。\")\n","\n","\n","        if not first_complete_sequence_found:\n","            print(\"\\n提示: 未找到任何完整的图序列进行Y值报告。\")\n","        # --- Y 值报告结束 ---\n","    else:\n","        print(\"\\n未生成任何图序列数据。\")\n","\n","\n","if __name__ == \"__main__\":\n","    # main_one_hour_test_with_weights() # Old call\n","    main_generate_12_hour_data()      # <<<< New call\n","    pass"],"metadata":{"id":"VxUb39SNdeCs"},"execution_count":null,"outputs":[]}]}